{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install git+https://github.com/beroguedou/SpecAugment.git\n",
    "#!pip install torchaudio\n",
    "#!pip install torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import time\n",
    "import librosa\n",
    "\n",
    "import warnings\n",
    "import pandas as pd\n",
    "from models import *\n",
    "from utils import *\n",
    "from decode import *\n",
    "import torch\n",
    "import torchaudio\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "seed_value = 2020\n",
    "np.random.seed(seed_value)\n",
    "torch.manual_seed(seed_value)\n",
    "torch.cuda.manual_seed_all(seed_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "limit = 80\n",
    "params = {'batch_size': None,\n",
    "          'shuffle': True,\n",
    "          'num_workers': 10,\n",
    "          'drop_last': True}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 347 ms, sys: 32.8 ms, total: 380 ms\n",
      "Wall time: 1.17 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "training_set = LibriSpeechDataset(limit=limit, n_frames=800, version='train-clean-360')\n",
    "dev_set = LibriSpeechDataset(limit=limit, n_frames=800, version='dev-clean')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[2.9673e-05, 2.9673e-05, 2.9673e-05,  ..., 8.6926e-04,\n",
       "           9.1071e-04, 9.5212e-04],\n",
       "          [4.4498e-06, 4.4498e-06, 4.4498e-06,  ..., 2.5194e+00,\n",
       "           2.4819e+00, 2.4445e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          ...,\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00]]]),\n",
       " tensor([  101,   101,  2045,  2001,  2625,  1997,  1037,  4306,  2055,  2085,\n",
       "          1998, 14163,  6894,  5289,  2106,  2025,  2031,  2000,  2562,  2067,\n",
       "          1037,  5481,  2004,  2002,  2441,  1996,  9445,  3460,  6031,  2988,\n",
       "          1996, 14460,  4214,  8721,  2000, 10767,  1998, 27468,  1996,  2221]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's see a single utterance\n",
    "\n",
    "LibriSpeechDataset(limit=limit, n_frames=800, version='train-clean-360')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "units = 64\n",
    "\n",
    "encoder = EncoderCONV2DRNN(device=device, hidden_size=units).to(device)\n",
    "decoder = DecoderATTRNN(vocab_size=30000, dec_units=units, hidden_size=units, \n",
    "                        encoder_timestamp=encoder.encoder_timestamp).to(device)\n",
    "\n",
    "encoder_optimizer = optim.Adam(encoder.parameters())\n",
    "decoder_optimizer = optim.Adam(decoder.parameters())\n",
    "\n",
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ====== ====== ====== ====== ====== ======\n",
      "      The model has 6029288 parameters\n",
      " ====== ====== ====== ====== ====== ======\n",
      "\n",
      "\n",
      "Epoch        1: 100%|████████████████████| 5/5 [01:20<00:00, 16.01s/it, Train loss 9.9365 Eval loss 9.7899]\n",
      "Epoch        2: 100%|████████████████████| 5/5 [01:21<00:00, 16.23s/it, Train loss 9.2872 Eval loss 8.7636]\n",
      "Epoch        3: 100%|████████████████████| 5/5 [01:22<00:00, 16.47s/it, Train loss 8.7807 Eval loss 8.2838]\n",
      "Epoch        4: 100%|████████████████████| 5/5 [01:21<00:00, 16.35s/it, Train loss 8.2911 Eval loss 7.8296]\n",
      "Epoch        5: 100%|████████████████████| 5/5 [01:21<00:00, 16.29s/it, Train loss 7.8049 Eval loss 7.4408]\n",
      "Epoch        6: 100%|████████████████████| 4/4 [01:16<00:00, 19.24s/it, Train loss 7.3704 Eval loss 7.1450]\n",
      "Epoch        7: 100%|████████████████████| 4/4 [01:17<00:00, 19.49s/it, Train loss 6.9989 Eval loss 6.8231]\n",
      "Epoch        8: 100%|████████████████████| 4/4 [01:16<00:00, 19.23s/it, Train loss 6.6392 Eval loss 6.5842]\n",
      "Epoch        9: 100%|████████████████████| 4/4 [01:16<00:00, 19.25s/it, Train loss 6.3321 Eval loss 6.3699]\n",
      "Epoch       10: 100%|████████████████████| 4/4 [01:17<00:00, 19.32s/it, Train loss 6.0674 Eval loss 6.1455]\n",
      "Epoch       11: 100%|████████████████████| 4/4 [01:17<00:00, 19.25s/it, Train loss 5.8379 Eval loss 6.0077]\n",
      "Epoch       12: 100%|████████████████████| 4/4 [01:17<00:00, 19.39s/it, Train loss 5.6706 Eval loss 5.9148]\n",
      "Epoch       13: 100%|████████████████████| 4/4 [01:17<00:00, 19.43s/it, Train loss 5.5312 Eval loss 5.8623]\n",
      "Epoch       14: 100%|████████████████████| 4/4 [01:16<00:00, 19.24s/it, Train loss 5.4650 Eval loss 5.8763]\n",
      "Epoch       15: 100%|████████████████████| 4/4 [01:18<00:00, 19.58s/it, Train loss 5.3949 Eval loss 5.8427]\n",
      "Epoch       16: 100%|████████████████████| 4/4 [01:17<00:00, 19.43s/it, Train loss 5.3320 Eval loss 5.8004]\n",
      "Epoch       17: 100%|████████████████████| 4/4 [01:17<00:00, 19.45s/it, Train loss 5.3305 Eval loss 5.8840]\n",
      "Epoch       18: 100%|████████████████████| 4/4 [01:17<00:00, 19.39s/it, Train loss 5.2828 Eval loss 5.8151]\n",
      "Epoch       19: 100%|████████████████████| 4/4 [01:17<00:00, 19.43s/it, Train loss 5.2381 Eval loss 5.8447]\n",
      "Epoch       20: 100%|████████████████████| 4/4 [01:17<00:00, 19.33s/it, Train loss 5.2281 Eval loss 6.0515]\n",
      "Epoch       21: 100%|████████████████████| 4/4 [01:18<00:00, 19.54s/it, Train loss 5.2622 Eval loss 5.8070]\n",
      "Epoch       22: 100%|████████████████████| 4/4 [01:17<00:00, 19.45s/it, Train loss 5.2366 Eval loss 5.9331]\n",
      "Epoch       23: 100%|████████████████████| 4/4 [01:18<00:00, 19.52s/it, Train loss 5.2384 Eval loss 6.4074]\n",
      "Epoch       24: 100%|████████████████████| 4/4 [01:17<00:00, 19.32s/it, Train loss 5.1293 Eval loss 5.7962]\n",
      "Epoch       25: 100%|████████████████████| 4/4 [01:17<00:00, 19.49s/it, Train loss 5.1209 Eval loss 5.7008]\n",
      "Epoch       26: 100%|████████████████████| 4/4 [01:18<00:00, 19.51s/it, Train loss 5.1850 Eval loss 5.7956]\n",
      "Epoch       27: 100%|████████████████████| 4/4 [01:18<00:00, 19.52s/it, Train loss 5.2426 Eval loss 6.1366]\n",
      "Epoch       28: 100%|████████████████████| 4/4 [01:17<00:00, 19.34s/it, Train loss 5.1017 Eval loss 5.8777]\n",
      "Epoch       29: 100%|████████████████████| 4/4 [01:18<00:00, 19.59s/it, Train loss 5.1736 Eval loss 6.3272]\n",
      "Epoch       30: 100%|████████████████████| 4/4 [01:17<00:00, 19.47s/it, Train loss 5.0645 Eval loss 6.0259]\n",
      "Epoch       31: 100%|████████████████████| 4/4 [01:17<00:00, 19.43s/it, Train loss 5.1595 Eval loss 6.1610]\n",
      "Epoch       32: 100%|████████████████████| 4/4 [01:18<00:00, 19.55s/it, Train loss 5.3635 Eval loss 5.9571]\n",
      "Epoch       33: 100%|████████████████████| 4/4 [01:16<00:00, 19.25s/it, Train loss 5.1629 Eval loss 6.0374]\n",
      "Epoch       34: 100%|████████████████████| 4/4 [01:17<00:00, 19.37s/it, Train loss 5.2162 Eval loss 5.9656]\n",
      "Epoch       35: 100%|████████████████████| 4/4 [01:17<00:00, 19.37s/it, Train loss 5.1013 Eval loss 6.0484]\n",
      "Epoch       36: 100%|████████████████████| 4/4 [01:17<00:00, 19.29s/it, Train loss 5.0381 Eval loss 6.1614]\n",
      "Epoch       37: 100%|████████████████████| 4/4 [01:17<00:00, 19.42s/it, Train loss 5.1966 Eval loss 6.3083]\n",
      "Epoch       38: 100%|████████████████████| 4/4 [01:17<00:00, 19.41s/it, Train loss 5.1995 Eval loss 6.3056]\n",
      "Epoch       39: 100%|████████████████████| 4/4 [01:17<00:00, 19.49s/it, Train loss 5.0152 Eval loss 6.4627]\n",
      "Epoch       40: 100%|████████████████████| 4/4 [01:17<00:00, 19.38s/it, Train loss 5.1101 Eval loss 6.2125]\n",
      "Epoch       41: 100%|████████████████████| 4/4 [01:17<00:00, 19.46s/it, Train loss 5.1037 Eval loss 6.2392]\n",
      "Epoch       42: 100%|████████████████████| 4/4 [01:17<00:00, 19.30s/it, Train loss 4.9541 Eval loss 6.1687]\n",
      "Epoch       43: 100%|████████████████████| 4/4 [01:18<00:00, 19.53s/it, Train loss 5.0666 Eval loss 6.1752]\n",
      "Epoch       44: 100%|████████████████████| 4/4 [01:17<00:00, 19.39s/it, Train loss 4.9362 Eval loss 6.1728]\n",
      "Epoch       45: 100%|████████████████████| 4/4 [01:17<00:00, 19.42s/it, Train loss 4.8874 Eval loss 6.4794]\n",
      "Epoch       46: 100%|████████████████████| 4/4 [01:18<00:00, 19.61s/it, Train loss 5.2240 Eval loss 6.3499]\n",
      "Epoch       47: 100%|████████████████████| 4/4 [01:18<00:00, 19.66s/it, Train loss 5.3207 Eval loss 6.2200]\n",
      "Epoch       48: 100%|████████████████████| 4/4 [01:17<00:00, 19.36s/it, Train loss 5.0839 Eval loss 6.5247]\n",
      "Epoch       49: 100%|████████████████████| 4/4 [01:17<00:00, 19.48s/it, Train loss 4.8522 Eval loss 6.6023]\n",
      "Epoch       50: 100%|████████████████████| 4/4 [01:17<00:00, 19.39s/it, Train loss 4.8262 Eval loss 6.2484]\n",
      "Epoch       51: 100%|████████████████████| 4/4 [01:18<00:00, 19.57s/it, Train loss 5.0849 Eval loss 6.2214]\n",
      "Epoch       52: 100%|████████████████████| 4/4 [01:17<00:00, 19.39s/it, Train loss 5.2626 Eval loss 6.1947]\n",
      "Epoch       53: 100%|████████████████████| 4/4 [01:17<00:00, 19.40s/it, Train loss 5.1710 Eval loss 6.2844]\n",
      "Epoch       54: 100%|████████████████████| 4/4 [01:16<00:00, 19.24s/it, Train loss 5.0716 Eval loss 6.2980]\n",
      "Epoch       55: 100%|████████████████████| 4/4 [01:18<00:00, 19.56s/it, Train loss 5.0061 Eval loss 6.2754]\n",
      "Epoch       56: 100%|████████████████████| 4/4 [01:17<00:00, 19.29s/it, Train loss 5.0847 Eval loss 5.9701]\n",
      "Epoch       57: 100%|████████████████████| 4/4 [01:17<00:00, 19.44s/it, Train loss 5.0221 Eval loss 6.5126]\n",
      "Epoch       58: 100%|████████████████████| 4/4 [01:17<00:00, 19.45s/it, Train loss 5.0352 Eval loss 6.2641]\n",
      "Epoch       59: 100%|████████████████████| 4/4 [01:17<00:00, 19.31s/it, Train loss 4.7779 Eval loss 6.1911]\n",
      "Epoch       60: 100%|████████████████████| 4/4 [01:17<00:00, 19.31s/it, Train loss 4.7683 Eval loss 6.1692]\n",
      "Epoch       61: 100%|████████████████████| 4/4 [01:17<00:00, 19.43s/it, Train loss 4.9823 Eval loss 6.6719]\n",
      "Epoch       62: 100%|████████████████████| 4/4 [01:17<00:00, 19.46s/it, Train loss 4.7541 Eval loss 6.2721]\n",
      "Epoch       63: 100%|████████████████████| 4/4 [01:17<00:00, 19.40s/it, Train loss 5.1706 Eval loss 6.1079]\n",
      "Epoch       64: 100%|████████████████████| 4/4 [01:17<00:00, 19.29s/it, Train loss 5.2683 Eval loss 6.0172]\n",
      "Epoch       65: 100%|████████████████████| 4/4 [01:17<00:00, 19.35s/it, Train loss 5.0833 Eval loss 6.1277]\n",
      "Epoch       66: 100%|████████████████████| 4/4 [01:17<00:00, 19.28s/it, Train loss 5.1444 Eval loss 6.3301]\n",
      "Epoch       67: 100%|████████████████████| 4/4 [01:17<00:00, 19.46s/it, Train loss 5.1540 Eval loss 6.5357]\n",
      "Epoch       68: 100%|████████████████████| 4/4 [01:17<00:00, 19.25s/it, Train loss 4.8256 Eval loss 5.8619]\n",
      "Epoch       69: 100%|████████████████████| 4/4 [01:17<00:00, 19.41s/it, Train loss 4.7437 Eval loss 5.8805]\n",
      "Epoch       70: 100%|████████████████████| 4/4 [01:17<00:00, 19.36s/it, Train loss 5.3542 Eval loss 6.2632]\n",
      "Epoch       71: 100%|████████████████████| 4/4 [01:17<00:00, 19.38s/it, Train loss 4.8946 Eval loss 6.1756]\n",
      "Epoch       72: 100%|████████████████████| 4/4 [01:16<00:00, 19.21s/it, Train loss 5.0583 Eval loss 5.9404]\n",
      "Epoch       73: 100%|████████████████████| 4/4 [01:17<00:00, 19.30s/it, Train loss 4.7248 Eval loss 5.8419]\n",
      "Epoch       74: 100%|████████████████████| 4/4 [01:17<00:00, 19.44s/it, Train loss 5.2995 Eval loss 6.4032]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch       75: 100%|████████████████████| 4/4 [01:17<00:00, 19.42s/it, Train loss 5.2196 Eval loss 6.5121]\n",
      "Epoch       76: 100%|████████████████████| 4/4 [01:18<00:00, 19.54s/it, Train loss 5.2108 Eval loss 6.7603]\n",
      "Epoch       77: 100%|████████████████████| 4/4 [01:17<00:00, 19.39s/it, Train loss 4.9524 Eval loss 6.0750]\n",
      "Epoch       78: 100%|████████████████████| 4/4 [01:17<00:00, 19.39s/it, Train loss 4.7605 Eval loss 6.6600]\n",
      "Epoch       79: 100%|████████████████████| 4/4 [01:17<00:00, 19.34s/it, Train loss 4.7309 Eval loss 6.0234]\n",
      "Epoch       80: 100%|████████████████████| 4/4 [01:17<00:00, 19.39s/it, Train loss 4.6999 Eval loss 5.8988]\n",
      "\n",
      "Time taken for the training 1.7451 hours\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "\n",
    "global_trainer(80, training_set, dev_set, params, encoder, decoder, encoder_optimizer,\n",
    "               decoder_optimizer, criterion, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfccs, references = training_set[1]\n",
    "tokenizer =  BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "references = [tokenizer.convert_ids_to_tokens(ind) for ind in references.numpy().tolist()]\n",
    "evaluate(mfccs.unsqueeze(0), references, 40, encoder, decoder, targ_lang_tokenizer=tokenizer, \n",
    "          device=device, beam_search=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vérifications\n",
    "\n",
    "# 1 - Data Augmentation\n",
    "# 2 - Encoder\n",
    "# 3 - Attention Mechanism Bahdanau Audio\n",
    "# 4 - Smoothing and Topk to the attention\n",
    "# 5 - Decoder \n",
    "# 6 - Métrique BLEU\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = nn.AvgPool2d(kernel_size=(3,3) , stride=(2,3), padding=(0,0))\n",
    "\n",
    "def dim_calcul_avg_pool2d(N, C_in, H_in, W_in, layer):\n",
    "\n",
    "    padding = layer.padding\n",
    "    kernel_size = layer.kernel_size\n",
    "    stride = layer.stride\n",
    "    C_out = C_in\n",
    "    H_out = 1 + (H_in + 2 * padding[0] - kernel_size[0]) // stride[0]\n",
    "    W_out = 1 + (W_in + 2 * padding[1] - kernel_size[1]) // stride[1]\n",
    "        \n",
    "    return (N, C_out, H_out, W_out)\n",
    "\n",
    "        \n",
    "    \n",
    "dim_calcul_avg_pool2d(16, 32, 35, 596, layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
