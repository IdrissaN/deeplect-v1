{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install git+https://github.com/beroguedou/SpecAugment.git\n",
    "#!pip install torchaudio\n",
    "#!pip install torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Bad key \"text.kerning_factor\" on line 4 in\n",
      "/home/user/miniconda/envs/py36/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test_patch.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.1.3/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import time\n",
    "import librosa\n",
    "\n",
    "import warnings\n",
    "import pandas as pd\n",
    "from models import *\n",
    "from utils import *\n",
    "from decode import *\n",
    "import torch\n",
    "import torchaudio\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "seed_value = 2020\n",
    "np.random.seed(seed_value)\n",
    "torch.manual_seed(seed_value)\n",
    "torch.cuda.manual_seed_all(seed_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "limit = 10000\n",
    "params = {'batch_size': None,\n",
    "          'shuffle': True,\n",
    "          'num_workers': 10,\n",
    "          'drop_last': True}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 337 ms, sys: 48.1 ms, total: 385 ms\n",
      "Wall time: 1.09 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "training_set = LibriSpeechDataset(limit=limit, n_frames=800, version='train-clean-360')\n",
    "dev_set = LibriSpeechDataset(limit=limit, n_frames=800, version='dev-clean')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see a single utterance\n",
    "\n",
    "LibriSpeechDataset(limit=limit, n_frames=800, version='train-clean-360')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "units = 256\n",
    "\n",
    "encoder = EncoderCONV2DRNN(device=device, hidden_size=units).to(device)\n",
    "decoder = DecoderATTRNN(vocab_size=30000, dec_units=units, hidden_size=units, \n",
    "                        encoder_timestamp=encoder.encoder_timestamp).to(device)\n",
    "\n",
    "encoder_optimizer = optim.Adam(encoder.parameters())\n",
    "decoder_optimizer = optim.Adam(decoder.parameters())\n",
    "\n",
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ====== ====== ====== ====== ====== ======\n",
      "      The model has 26799272 parameters\n",
      " ====== ====== ====== ====== ====== ======\n",
      "\n",
      "\n",
      "Epoch        1: 100%|████████████████████| 625/625 [36:59<00:00,  3.55s/it, Train loss 6.3545 Eval loss 4.6890]\n",
      "Epoch        2: 100%|████████████████████| 625/625 [36:57<00:00,  3.55s/it, Train loss 6.1688 Eval loss 4.2299]\n",
      "Epoch        3: 100%|████████████████████| 625/625 [36:55<00:00,  3.54s/it, Train loss 6.1230 Eval loss 4.1871]\n",
      "Epoch        4: 100%|████████████████████| 625/625 [36:57<00:00,  3.55s/it, Train loss 6.0776 Eval loss 4.1615]\n",
      "Epoch        5: 100%|████████████████████| 625/625 [36:54<00:00,  3.54s/it, Train loss 6.0621 Eval loss 4.2168]\n",
      "Epoch        6: 100%|████████████████████| 625/625 [36:56<00:00,  3.55s/it, Train loss 6.0040 Eval loss 4.1149]\n",
      "Epoch        7: 100%|████████████████████| 625/625 [36:53<00:00,  3.54s/it, Train loss 5.9606 Eval loss 4.1395]\n",
      "Epoch        8: 100%|████████████████████| 625/625 [36:54<00:00,  3.54s/it, Train loss 5.9445 Eval loss 4.0711]\n",
      "Epoch        9: 100%|████████████████████| 625/625 [36:53<00:00,  3.54s/it, Train loss 5.9266 Eval loss 4.3364]\n",
      "Epoch       10: 100%|████████████████████| 625/625 [36:55<00:00,  3.54s/it, Train loss 5.9240 Eval loss 4.0338]\n",
      "\n",
      "Time taken for the training 6.1603 hours\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "\n",
    "global_trainer(10, training_set, dev_set, params, encoder, decoder, encoder_optimizer,\n",
    "               decoder_optimizer, criterion, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: ['[CLS]', '[CLS]', 'what', 'did', 'you', 'do', 'next', 'i', 'awakened', 'with', 'a', 'sudden', 'start', 'just', 'before', 'six', 'o', \"'\", 'clock', 'i', 'had', 'not', 'set', 'an', 'alarm', 'though', 'i', 'wanted', 'to', 'get', 'up', 'early', 'to', 'do', 'a', 'little', 'repair', 'job', 'i', 'had']\n",
      "\n",
      "\n",
      "Predicted translation: ['[CLS]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "\n",
      "\n",
      "Bleu score: 2.3295942588771784e-155\n"
     ]
    }
   ],
   "source": [
    "mfccs, references = training_set[1]\n",
    "tokenizer =  BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "references = [tokenizer.convert_ids_to_tokens(ind) for ind in references.numpy().tolist()]\n",
    "evaluate(mfccs.unsqueeze(0), references, 40, encoder, decoder, targ_lang_tokenizer=tokenizer, \n",
    "          device=device, beam_search=True, beam_width=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vérifications\n",
    "\n",
    "# 1 - Data Augmentation\n",
    "# 2 - Encoder\n",
    "# 3 - Attention Mechanism Bahdanau Audio\n",
    "# 4 - Smoothing and Topk to the attention\n",
    "# 5 - Decoder \n",
    "# 6 - Métrique BLEU\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: The directory '/home/user/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip freeze > recquirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
